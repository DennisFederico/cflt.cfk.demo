apiVersion: platform.confluent.io/v1beta1
kind: Connect
metadata:
  name: extra-connect
  namespace: confluent
spec:
  image:
    application: confluentinc/cp-server-connect:7.9.1
    init: confluentinc/confluent-init-container:2.11.1
  replicas: 1
  # podTemplate:
  #   topologySpreadConstraints:
  #     - maxSkew: 1
  #       topologyKey: kubernetes.io/hostname
  #       whenUnsatisfiable: ScheduleAnyway
  #       labelSelector:
  #         matchLabels:
  #           type: kafka-pods
  # mountedSecrets:
  #   - secretRef: cc-root-jks
  #     keyItems:
  #     - key: cc_truststore.jks
  #       path: cc_truststore.jks
  build:
    type: onDemand
    onDemand:
      plugins:
        confluentHub:
          - name: kafka-connect-datagen
            owner: confluentinc
            version: latest
          - name: connect-transforms
            owner: confluentinc
            version: latest
  tls:
    autoGeneratedCerts: true
  authentication:
    type: basic
    basic:
      secretRef: basic-users
  externalAccess:
    type: nodePort
    nodePort:
      host: connect.confluent.demo.com
      nodePortOffset: 30700
  #   type: loadBalancer
  #   loadBalancer:  
  #     domain: confluent.demo.com
  #     prefix: connect
  authorization:
    type: rbac
  dependencies:
    kafka:
      bootstrapEndpoint: kafka:9071
      tls:
        enabled: true
        # ignoreTrustStoreConfig: true
      authentication:
        type: mtls
        sslClientAuthentication: true
    mds:
      endpoint: https://kafka.confluent.svc.cluster.local:8090
      tokenKeyPair:
        secretRef: mds-key-pair
      tls:
        enabled: true
        # ignoreTrustStoreConfig: true
      authentication:
        type: mtls
        sslClientAuthentication: true
      # authentication:
      #   type: bearer
      #   bearer:
      #     secretRef: connect-bearer
      #   sslClientAuthentication: false
    schemaRegistry:
      url: https://schemaregistry.confluent.svc.cluster.local:8081
      tls:
        enabled: true
      authentication:
        type: basic
        basic:
          secretRef: connect-basic-creds
  metrics:
    prometheus:
      whitelist:
        # Engine Application Versioning Info
        - kafka.connect:type=app-info,client-id=*
        # Connect Worker Rebalancing info
        - kafka.connect:type=connect-worker-rebalance-metrics
        # Connect Co-ordinator Info
        - kafka.connect:type=connect-coordinator-metrics,*
        - kafka.connect:type=connect-metrics,*
        # Worker level metrics for the aggregate as well as per connector level
        - kafka.connect:type=connect-worker-metrics
        - kafka.connect:type=connect-worker-metrics,*
        # Engine Connector Versioning Info
        - kafka.connect:type=connector-metrics,*
        # Task level metrics for every connector running in the current node.
        - kafka.connect:type=*-task-metrics,*
        - kafka.connect:type=task-error-metrics,*
        #  Confluent Replicator JMX Stats
        - confluent.replicator:type=confluent-replicator-task-metrics,*
        # The two lines below are used to pull the Kafka Client Producer & consumer metrics from Connect Workers.
        # If you care about Producer/Consumer metrics for Connect, please uncomment 2 lines below.
        # Please note that this increases the scrape duration by about 1-2 seconds as it needs to parse a lot of data.
        - "kafka.consumer:*"
        - "kafka.producer:*"
        - "kafka.secret.registry:*"
        - "kafka.connect.oracle.cdc:*"
        - "com.mongodb.kafka.connect:*"
        - "debezium.mysql:*"
        - "debezium.sql_server:*"
        - "debezium.mongodb:*"
        - "debezium.postgres:*"
      blacklist:
        # This will ignore the admin client metrics from KSQL server and will blacklist certain metrics
        # that do not make sense for ingestion.
        - "kafka.admin.client:*"
        - "kafka.consumer:type=*,id=*"
        - "kafka.producer:type=*,id=*"
        - "kafka.producer:client-id=confluent.monitoring*,*"
        - "kafka.*:type=kafka-metrics-count,*"
        # - "kafka.*:type=app-info,*"
      rules:
        # "kafka.schema.registry:type=app-info,id=*"
        - pattern: "kafka.connect<type=app-info, client-id=(.+)><>(.+): (.+)"
          name: "kafka_connect_app_info"
          value: "1"
          labels:
            client-id: "$1"
            $2: "$3"
          type: UNTYPED
        # kafka.connect:type=connect-worker-rebalance-metrics
        - pattern: "kafka.connect<type=connect-worker-rebalance-metrics><>([^:]+)"
          name: "kafka_connect_connect_worker_rebalance_metrics_$1"
        # kafka.connect:type=connect-coordinator-metrics,client-id=*
        # kafka.connect:type=connect-metrics,client-id=*
        - pattern: "kafka.connect<type=(.+), client-id=(.+)><>([^:]+)"
          name: kafka_connect_$1_$3
          labels:
            client_id: $2
        # kafka.connect:type=connect-worker-metrics
        - pattern: "kafka.connect<type=connect-worker-metrics><>([^:]+)"
          name: kafka_connect_connect_worker_metrics_$1
          labels:
            connector: "aggregate"
        # kafka.connect:type=connect-worker-metrics,connector=*
        - pattern: "kafka.connect<type=connect-worker-metrics, connector=(.+)><>([^:]+)"
          name: kafka_connect_connect_worker_metrics_$2
          labels:
            connector: $1
        # kafka.connect:type=connector-metrics,connector=*
        - pattern: "kafka.connect<type=connector-metrics, connector=(.+)><>(.+): (.+)"
          value: "1"
          name: kafka_connect_connector_metrics
          labels:
            connector: $1
            $2: $3
          type: UNTYPED